{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from IPython.utils import io\n",
    "import warnings\n",
    "import statistics\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in optical flow rgb images file\n",
    "images = pd.read_pickle('../data/images.pkl')\n",
    "images = images.reset_index()\n",
    "#read labels\n",
    "labels = None\n",
    "with open(\"../speedchallenge/data/train.txt\") as f:\n",
    "    #we drop the first label cause optical flow is two images}\n",
    "    labels = (list(map(float, f.read().splitlines()))[1:])\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model class\n",
    "class Small(nn.Module):\n",
    "    \n",
    "    def __init__(self, batch_size, dim):\n",
    "        \n",
    "        super(Small, self).__init__()\n",
    "        #initialize parameters\n",
    "        self.batch_size = batch_size\n",
    "        self.dim = dim\n",
    "        #representation layer\n",
    "        self.conv1 = nn.Conv2d(3,12,3,stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(12)\n",
    "        self.conv2 = nn.Conv2d(12,32,5,stride=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32,64,3,stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64,128,5,stride=1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        #decision layer\n",
    "        self.fc1 = nn.Linear(dim, 2**10)\n",
    "        self.fc2 = nn.Linear(2**10, 2**8)\n",
    "        self.fc3 = nn.Linear(2**8, 2**6)\n",
    "        self.fc4 = nn.Linear(2**6, 2**0)\n",
    "        #droput layers\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "        self.dropout4 = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #apply convolutions\n",
    "        x = F.relu(F.max_pool2d(self.bn1(self.conv1(x)),2))\n",
    "        x = F.relu(F.max_pool2d(self.bn2(self.conv2(x)),2))\n",
    "        x = F.relu(F.max_pool2d(self.bn3(self.conv3(x)),2))\n",
    "        x = F.relu(F.max_pool2d(self.bn4(self.conv4(x)),2))\n",
    "        #apply decision layers\n",
    "        x = x.reshape(self.batch_size, -1)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout4(x)\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Small(\n",
       "  (conv1): Conv2d(3, 12, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(12, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=4480, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (dropout1): Dropout(p=0.2, inplace=False)\n",
       "  (dropout2): Dropout(p=0.2, inplace=False)\n",
       "  (dropout3): Dropout(p=0.2, inplace=False)\n",
       "  (dropout4): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "dim = 4480\n",
    "n_train_examples = 10000\n",
    "n_val_examples = 500\n",
    "n_epochs = 100\n",
    "lr=1e-2\n",
    "\n",
    "#initialize model\n",
    "model = Small(batch_size=batch_size, dim=dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.99)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#use gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#create prediction model\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create data loader\n",
    "def get_loader(n, batch_size):\n",
    "    #sample n images above sequence length index\n",
    "    sample_images = images.sample(n).index\n",
    "    vectors = list(images.iloc[idx].Image.reshape(480,640,3).permute(2,0,1).cpu().numpy() for idx in tqdm(sample_images))\n",
    "    targets = list(labels[idx] for idx in tqdm(sample_images))\n",
    "    return vectors, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loader classes\n",
    "class MyTrainDataloader(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = list(zip(torch.tensor(x_train),torch.tensor(y_train)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx][0], self.data[idx][1] \n",
    "    \n",
    "class MyValDataLoader(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = list(zip(torch.tensor(x_val),torch.tensor(y_val)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx][0], self.data[idx][1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:01<00:00, 7018.20it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 1995956.98it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 8058.34it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 1744718.80it/s]\n"
     ]
    }
   ],
   "source": [
    "#create train and test data loaders\n",
    "x_train, y_train = get_loader(n_train_examples, batch_size)\n",
    "x_val, y_val = get_loader(n_val_examples, batch_size)\n",
    "\n",
    "train_data = MyTrainDataloader()\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=2,\n",
    "                                           batch_size=batch_size,\n",
    "                                           drop_last=True)\n",
    "\n",
    "val_data = MyValDataLoader()\n",
    "val_loader = torch.utils.data.DataLoader(val_data,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=2,\n",
    "                                           batch_size=batch_size,\n",
    "                                           drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#for switching model between train and eval without cell output\n",
    "def train():\n",
    "    with io.capture_output() as captured:\n",
    "        model.train()\n",
    "\n",
    "def test():\n",
    "    with io.capture_output() as captured:\n",
    "        model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100.............\n",
      "Train MSE: 540.7302\n",
      "Val MSE: 36.0124 \n",
      "\n",
      "Epoch: 2/100.............\n",
      "Train MSE: 32.0933\n",
      "Val MSE: 28.2398 \n",
      "\n",
      "Epoch: 3/100.............\n",
      "Train MSE: 28.7871\n",
      "Val MSE: 39.7658 \n",
      "\n",
      "Epoch: 4/100.............\n",
      "Train MSE: 25.3637\n",
      "Val MSE: 35.0122 \n",
      "\n",
      "Epoch: 5/100.............\n",
      "Train MSE: 22.7338\n",
      "Val MSE: 41.5122 \n",
      "\n",
      "Epoch: 6/100.............\n",
      "Train MSE: 22.5792\n",
      "Val MSE: 20.7840 \n",
      "\n",
      "Epoch: 7/100.............\n",
      "Train MSE: 21.5742\n",
      "Val MSE: 30.6513 \n",
      "\n",
      "Epoch: 8/100.............\n",
      "Train MSE: 20.6812\n",
      "Val MSE: 28.3541 \n",
      "\n",
      "Epoch: 9/100.............\n",
      "Train MSE: 19.2793\n",
      "Val MSE: 17.3401 \n",
      "\n",
      "Epoch: 10/100.............\n",
      "Train MSE: 18.3916\n",
      "Val MSE: 18.4688 \n",
      "\n",
      "Epoch: 11/100.............\n",
      "Train MSE: 17.6517\n",
      "Val MSE: 21.7686 \n",
      "\n",
      "Epoch: 12/100.............\n",
      "Train MSE: 16.2746\n",
      "Val MSE: 31.6230 \n",
      "\n",
      "Epoch: 13/100.............\n",
      "Train MSE: 15.9963\n",
      "Val MSE: 21.5966 \n",
      "\n",
      "Epoch: 14/100.............\n",
      "Train MSE: 16.7370\n",
      "Val MSE: 20.7712 \n",
      "\n",
      "Epoch: 15/100.............\n",
      "Train MSE: 15.3034\n",
      "Val MSE: 44.1694 \n",
      "\n",
      "Epoch: 16/100.............\n",
      "Train MSE: 15.9298\n",
      "Val MSE: 14.3383 \n",
      "\n",
      "Epoch: 17/100.............\n",
      "Train MSE: 14.1196\n",
      "Val MSE: 22.9579 \n",
      "\n",
      "Epoch: 18/100.............\n",
      "Train MSE: 14.1013\n",
      "Val MSE: 19.4985 \n",
      "\n",
      "Epoch: 19/100.............\n",
      "Train MSE: 13.1907\n",
      "Val MSE: 26.4700 \n",
      "\n",
      "Epoch: 20/100.............\n",
      "Train MSE: 13.2838\n",
      "Val MSE: 28.4174 \n",
      "\n",
      "Epoch: 21/100.............\n",
      "Train MSE: 12.6131\n",
      "Val MSE: 12.9607 \n",
      "\n",
      "Epoch: 22/100.............\n",
      "Train MSE: 13.4790\n",
      "Val MSE: 15.7248 \n",
      "\n",
      "Epoch: 23/100.............\n",
      "Train MSE: 11.6403\n",
      "Val MSE: 17.1798 \n",
      "\n",
      "Epoch: 24/100.............\n",
      "Train MSE: 11.4568\n",
      "Val MSE: 21.6209 \n",
      "\n",
      "Epoch: 25/100.............\n",
      "Train MSE: 11.0242\n",
      "Val MSE: 14.9817 \n",
      "\n",
      "Epoch: 26/100.............\n",
      "Train MSE: 11.7144\n",
      "Val MSE: 9.1186 \n",
      "\n",
      "Epoch: 27/100.............\n",
      "Train MSE: 11.2070\n",
      "Val MSE: 10.9594 \n",
      "\n",
      "Epoch: 28/100.............\n",
      "Train MSE: 11.2184\n",
      "Val MSE: 11.2048 \n",
      "\n",
      "Epoch: 29/100.............\n",
      "Train MSE: 10.6208\n",
      "Val MSE: 26.2990 \n",
      "\n",
      "Epoch: 30/100.............\n",
      "Train MSE: 10.6035\n",
      "Val MSE: 10.8392 \n",
      "\n",
      "Epoch: 31/100.............\n",
      "Train MSE: 9.9267\n",
      "Val MSE: 10.4479 \n",
      "\n",
      "Epoch: 32/100.............\n",
      "Train MSE: 9.7776\n",
      "Val MSE: 29.8251 \n",
      "\n",
      "Epoch: 33/100.............\n",
      "Train MSE: 9.4328\n",
      "Val MSE: 8.1679 \n",
      "\n",
      "Epoch: 34/100.............\n",
      "Train MSE: 9.3869\n",
      "Val MSE: 11.1336 \n",
      "\n",
      "Epoch: 35/100.............\n",
      "Train MSE: 9.1018\n",
      "Val MSE: 9.5063 \n",
      "\n",
      "Epoch: 36/100.............\n",
      "Train MSE: 9.0691\n",
      "Val MSE: 12.7816 \n",
      "\n",
      "Epoch: 37/100.............\n",
      "Train MSE: 8.4730\n",
      "Val MSE: 12.3231 \n",
      "\n",
      "Epoch: 38/100.............\n",
      "Train MSE: 9.4016\n",
      "Val MSE: 7.4998 \n",
      "\n",
      "Epoch: 39/100.............\n",
      "Train MSE: 8.8970\n",
      "Val MSE: 11.3259 \n",
      "\n",
      "Epoch: 40/100.............\n",
      "Train MSE: 9.0531\n",
      "Val MSE: 16.7792 \n",
      "\n",
      "Epoch: 41/100.............\n",
      "Train MSE: 8.0181\n",
      "Val MSE: 9.3580 \n",
      "\n",
      "Epoch: 42/100.............\n",
      "Train MSE: 8.1566\n",
      "Val MSE: 13.6689 \n",
      "\n",
      "Epoch: 43/100.............\n",
      "Train MSE: 8.0648\n",
      "Val MSE: 14.7251 \n",
      "\n",
      "Epoch: 44/100.............\n",
      "Train MSE: 8.1897\n",
      "Val MSE: 10.0698 \n",
      "\n",
      "Epoch: 45/100.............\n",
      "Train MSE: 7.8069\n",
      "Val MSE: 11.7114 \n",
      "\n",
      "Epoch: 46/100.............\n",
      "Train MSE: 7.9405\n",
      "Val MSE: 12.1258 \n",
      "\n",
      "Epoch: 47/100.............\n",
      "Train MSE: 7.8066\n",
      "Val MSE: 14.8659 \n",
      "\n",
      "Epoch: 48/100.............\n",
      "Train MSE: 8.0204\n",
      "Val MSE: 10.5283 \n",
      "\n",
      "Epoch: 49/100.............\n",
      "Train MSE: 7.6672\n",
      "Val MSE: 8.7291 \n",
      "\n",
      "Epoch: 50/100.............\n",
      "Train MSE: 7.9222\n",
      "Val MSE: 11.9786 \n",
      "\n",
      "Epoch: 51/100.............\n",
      "Train MSE: 7.6298\n",
      "Val MSE: 9.3397 \n",
      "\n",
      "Epoch: 52/100.............\n",
      "Train MSE: 7.4319\n",
      "Val MSE: 13.2042 \n",
      "\n",
      "Epoch: 53/100.............\n",
      "Train MSE: 7.4110\n",
      "Val MSE: 10.6069 \n",
      "\n",
      "Epoch: 54/100.............\n",
      "Train MSE: 7.2180\n",
      "Val MSE: 21.0796 \n",
      "\n",
      "Epoch: 55/100.............\n",
      "Train MSE: 7.5680\n",
      "Val MSE: 11.0101 \n",
      "\n",
      "Epoch: 56/100.............\n",
      "Train MSE: 7.3287\n",
      "Val MSE: 9.8307 \n",
      "\n",
      "Epoch: 57/100.............\n",
      "Train MSE: 7.0231\n",
      "Val MSE: 8.4455 \n",
      "\n",
      "Epoch: 58/100.............\n",
      "Train MSE: 7.1862\n",
      "Val MSE: 10.5482 \n",
      "\n",
      "Epoch: 59/100.............\n",
      "Train MSE: 6.9575\n",
      "Val MSE: 10.9738 \n",
      "\n",
      "Epoch: 60/100.............\n",
      "Train MSE: 7.3012\n",
      "Val MSE: 8.3785 \n",
      "\n",
      "Epoch: 61/100.............\n",
      "Train MSE: 6.9395\n",
      "Val MSE: 8.7870 \n",
      "\n",
      "Epoch: 62/100.............\n",
      "Train MSE: 7.2613\n",
      "Val MSE: 11.4458 \n",
      "\n",
      "Epoch: 63/100.............\n",
      "Train MSE: 6.5653\n",
      "Val MSE: 7.4055 \n",
      "\n",
      "Epoch: 64/100.............\n",
      "Train MSE: 7.0668\n",
      "Val MSE: 10.2503 \n",
      "\n",
      "Epoch: 65/100.............\n",
      "Train MSE: 7.3745\n",
      "Val MSE: 13.6688 \n",
      "\n",
      "Epoch: 66/100.............\n",
      "Train MSE: 6.7483\n",
      "Val MSE: 7.0486 \n",
      "\n",
      "Epoch: 67/100.............\n",
      "Train MSE: 6.8673\n",
      "Val MSE: 9.4793 \n",
      "\n",
      "Epoch: 68/100.............\n",
      "Train MSE: 6.4138\n",
      "Val MSE: 11.3830 \n",
      "\n",
      "Epoch: 69/100.............\n",
      "Train MSE: 6.8391\n",
      "Val MSE: 8.5067 \n",
      "\n",
      "Epoch: 70/100.............\n",
      "Train MSE: 6.6840\n",
      "Val MSE: 8.2511 \n",
      "\n",
      "Epoch: 71/100.............\n",
      "Train MSE: 6.7311\n",
      "Val MSE: 19.4260 \n",
      "\n",
      "Epoch: 72/100.............\n",
      "Train MSE: 6.5308\n",
      "Val MSE: 8.5847 \n",
      "\n",
      "Epoch: 73/100.............\n",
      "Train MSE: 6.4714\n",
      "Val MSE: 8.5365 \n",
      "\n",
      "Epoch: 74/100.............\n",
      "Train MSE: 6.4380\n",
      "Val MSE: 8.5510 \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9379/1912234097.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#track loss values\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "#begin training\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    #train\n",
    "    train()\n",
    "    train_loss = 0\n",
    "    for batch in train_loader:\n",
    "        x, y = batch[0], batch[1]\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(torch.tensor(x).float().cuda())\n",
    "        loss = criterion(pred.flatten(), torch.tensor(y).float().cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss+=loss.item()\n",
    "    scheduler.step()\n",
    "    \n",
    "    #validate\n",
    "    if epoch%1 == 0:\n",
    "        test()\n",
    "        val_loss = 0\n",
    "        for batch in val_loader:\n",
    "            x, y = batch[0], batch[1]\n",
    "            pred = model(torch.tensor(x).float().cuda())\n",
    "            loss = criterion(pred.flatten(), torch.tensor(y).float().cuda())\n",
    "            val_loss+=loss.item()\n",
    "        \n",
    "        #print progress\n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs))\n",
    "        print(\"Train MSE: {:.4f}\".format(train_loss/len(train_loader)))\n",
    "        print(\"Val MSE: {:.4f}\".format(val_loss/len(val_loader)), \"\\n\")\n",
    "        \n",
    "        #track loss\n",
    "        train_losses.append(train_loss/len(train_loader))\n",
    "        val_losses.append(val_loss/len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(list(zip(train_losses,val_losses)), columns=['Train MSE', 'Val MSE']).to_csv('../charts/medium.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
