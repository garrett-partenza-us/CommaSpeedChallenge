{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from IPython.utils import io\n",
    "import warnings\n",
    "import statistics\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in optical flow rgb images file\n",
    "images = pd.read_pickle('../data/images.pkl')\n",
    "images = images.reset_index()\n",
    "#read labels\n",
    "labels = None\n",
    "with open(\"../speedchallenge/data/train.txt\") as f:\n",
    "    #we drop the first label cause optical flow is two images\n",
    "    labels = (list(map(float, f.read().splitlines()))[1:])\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model class\n",
    "class Small(nn.Module):\n",
    "    \n",
    "    def __init__(self, batch_size, dim):\n",
    "        \n",
    "        super(Small, self).__init__()\n",
    "        #initialize parameters\n",
    "        self.batch_size = batch_size\n",
    "        self.dim = dim\n",
    "        #decision layer\n",
    "        self.fc1 = nn.Linear(dim, 2**11)\n",
    "        self.fc2 = nn.Linear(2**11, 2**8)\n",
    "        self.fc3 = nn.Linear(2**8, 1)\n",
    "        #droput layers\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.dropout3 = nn.Dropout(0.4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #apply decision layers\n",
    "        x = x.reshape(self.batch_size, -1)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Small(\n",
       "  (fc1): Linear(in_features=384000, out_features=2048, bias=True)\n",
       "  (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (dropout1): Dropout(p=0.2, inplace=False)\n",
       "  (dropout2): Dropout(p=0.3, inplace=False)\n",
       "  (dropout3): Dropout(p=0.4, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "dim = 384000\n",
    "n_train_examples = 100\n",
    "n_test_examples = 25\n",
    "n_epochs = 100\n",
    "lr=1e-2\n",
    "\n",
    "#initialize model\n",
    "model = Small(batch_size=batch_size, dim=dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.97)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#use gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#create prediction model\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "cnn = EfficientNet.from_pretrained('efficientnet-b0').to(device)\n",
    "\n",
    "#function to create data loader\n",
    "def get_loader(n, batch_size):\n",
    "    #sample n images above sequence length index\n",
    "    sample_images = images.sample(n).index\n",
    "    \n",
    "    vectors = list(cnn.extract_features(images.iloc[idx].Image.reshape(1,3,480,640).float().cuda()).detach().cpu().flatten().numpy() for idx in tqdm(sample_images))\n",
    "    targets = list(labels[idx] for idx in tqdm(sample_images))\n",
    "    return vectors, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loader classes\n",
    "class MyTrainDataloader(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.images = torch.Tensor(x_train)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(x_train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], y_train[idx]\n",
    "    \n",
    "class MyTestDataLoader(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.images = torch.Tensor(x_test)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(x_test)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], y_test[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 43.24it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 707302.53it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 43.29it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 242165.36it/s]\n"
     ]
    }
   ],
   "source": [
    "#create train and test data loaders\n",
    "x_train, y_train = get_loader(n_train_examples, batch_size)\n",
    "x_test, y_test = get_loader(n_test_examples, batch_size)\n",
    "\n",
    "train_data = MyTrainDataloader()\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=2,\n",
    "                                           batch_size=batch_size,\n",
    "                                           drop_last=True)\n",
    "\n",
    "test_data = MyTestDataLoader()\n",
    "test_loader = torch.utils.data.DataLoader(test_data,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=2,\n",
    "                                           batch_size=batch_size,\n",
    "                                           drop_last=True)\n",
    "\n",
    "cnn.cpu()\n",
    "del cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#for switching model between train and eval without cell output\n",
    "def train():\n",
    "    with io.capture_output() as captured:\n",
    "        model.train()\n",
    "\n",
    "def test():\n",
    "    with io.capture_output() as captured:\n",
    "        model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.93 GiB (GPU 0; 11.91 GiB total capacity; 8.79 GiB already allocated; 2.29 GiB free; 8.84 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22229/3016110516.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mbatch_train_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     79\u001b[0m                     \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'exp_avg'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0;31m# Exponential moving average of squared gradient values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                     \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'exp_avg_sq'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                         \u001b[0;31m# Maintains max of all exp. moving avg. of sq. grad. values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.93 GiB (GPU 0; 11.91 GiB total capacity; 8.79 GiB already allocated; 2.29 GiB free; 8.84 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#track loss values\n",
    "batch_train_loss = []\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "#begin training\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    #train\n",
    "    train()\n",
    "    train_loss = []\n",
    "    for batch in train_loader:\n",
    "        x, y = batch[0], batch[1]\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(torch.tensor(x).cuda())\n",
    "        loss = criterion(pred.flatten(), torch.tensor(y).float().cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "        batch_train_loss.append(loss.item())\n",
    "    scheduler.step()\n",
    "    \n",
    "    #validate\n",
    "    if epoch%1 == 0:\n",
    "        test()\n",
    "        val_loss = []\n",
    "        for batch in test_loader:\n",
    "            x, y = batch[0], batch[1]\n",
    "            pred = model(torch.tensor(x).cuda())\n",
    "            loss = criterion(pred.flatten(), torch.tensor(y).float().cuda())\n",
    "            val_loss.append(loss.item())\n",
    "        \n",
    "        #print progress\n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs))\n",
    "        print(\"Train MSE: {:.4f}\".format(statistics.mean(train_loss)))\n",
    "        print(\"Val MSE: {:.4f}\".format(statistics.mean(val_loss)), \"\\n\")\n",
    "        \n",
    "        #track loss\n",
    "        train_loss.append(statistics.mean(train_loss))\n",
    "        val_loss.append(statistics.mean(val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
